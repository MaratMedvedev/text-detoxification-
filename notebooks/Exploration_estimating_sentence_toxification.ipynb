{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZh4QJxMyKWY",
        "outputId": "e07e4c84-f901-47f0-cfcb-ecfa5394fa29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"unitary/toxic-bert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"unitary/toxic-bert\")"
      ],
      "metadata": {
        "id": "ixH9bDxox16v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-642401067cea>:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  torch.nn.functional.softmax(outputs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7704, 0.0248, 0.0663, 0.0268, 0.0672, 0.0445]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "input_text = \"So cute dog!\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Perform inference with the model\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids)\n",
        "outputs = outputs[0]\n",
        "torch.nn.functional.softmax(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm-a5bNsx16y",
        "outputId": "0b230e41-85f3-401d-bbbb-267a1093b429"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This too heavy model, I will try more lightweight model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "wS566425x16y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_checkpoint = 'cointegrated/rubert-tiny-toxicity'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "\n",
        "def text2toxicity(text, aggregate=True):\n",
        "    \"\"\" Calculate toxicity of a text (if aggregate=True) or a vector of toxicity aspects (if aggregate=False)\"\"\"\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(model.device)\n",
        "        proba = torch.sigmoid(model(**inputs).logits).cpu().numpy()\n",
        "    if isinstance(text, str):\n",
        "        proba = proba[0]\n",
        "    if aggregate:\n",
        "        return 1 - proba.T[0] * (1 - proba.T[-1])\n",
        "    return proba"
      ],
      "metadata": {
        "id": "vID-GQq0x16z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will use translation and references texts and their toxicity level to train model.  "
      ],
      "metadata": {
        "id": "uAbMMCvvctjJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('filtered.tsv', sep='\\t')\n",
        "data.drop(len(data) - 1, axis=0, inplace=True)\n",
        "data1 = data.iloc[:, [2, 6]]\n",
        "data2 = data.iloc[:, [1, 5]]\n",
        "data1.columns = ['text', 'toxicity_score']\n",
        "data2.columns = ['text', 'toxicity_score']"
      ],
      "metadata": {
        "id": "lG2NRpoDx16z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([data1, data2], axis=0)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Znb1quVUc5Sq",
        "outputId": "1f725ebd-2dba-4922-e990-724f6cb275b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  toxicity_score\n",
              "0       if Alkar floods her with her mental waste, it ...        0.981983\n",
              "1                             you're becoming disgusting.        0.999039\n",
              "2                           well, we can spare your life.        0.985068\n",
              "3                            monkey, you have to wake up.        0.994215\n",
              "4                              I have orders to kill her.        0.999348\n",
              "...                                                   ...             ...\n",
              "577771  I thought American men were bad enough, but no...        0.999624\n",
              "577772  You didn't know that Estelle had stolen some f...        0.000121\n",
              "577773                    It'il suck the life out of you!        0.996124\n",
              "577774                   I can't fuckin' take that, bruv.        0.984538\n",
              "577775  They called me a fucking hero. The truth is I ...        0.991945\n",
              "\n",
              "[1155552 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ceeeee65-de8d-4fdc-8e5d-9f9b57abe800\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxicity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
              "      <td>0.981983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>you're becoming disgusting.</td>\n",
              "      <td>0.999039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well, we can spare your life.</td>\n",
              "      <td>0.985068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>monkey, you have to wake up.</td>\n",
              "      <td>0.994215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I have orders to kill her.</td>\n",
              "      <td>0.999348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577771</th>\n",
              "      <td>I thought American men were bad enough, but no...</td>\n",
              "      <td>0.999624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577772</th>\n",
              "      <td>You didn't know that Estelle had stolen some f...</td>\n",
              "      <td>0.000121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577773</th>\n",
              "      <td>It'il suck the life out of you!</td>\n",
              "      <td>0.996124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577774</th>\n",
              "      <td>I can't fuckin' take that, bruv.</td>\n",
              "      <td>0.984538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577775</th>\n",
              "      <td>They called me a fucking hero. The truth is I ...</td>\n",
              "      <td>0.991945</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1155552 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceeeee65-de8d-4fdc-8e5d-9f9b57abe800')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ceeeee65-de8d-4fdc-8e5d-9f9b57abe800 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ceeeee65-de8d-4fdc-8e5d-9f9b57abe800');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-77b8fd19-9475-4000-baad-a63198d3c897\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77b8fd19-9475-4000-baad-a63198d3c897')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-77b8fd19-9475-4000-baad-a63198d3c897 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['if Alkar floods her with her mental waste, it would explain the high levels of neurotransmitter.', \"you're becoming disgusting.\", 'well, we can spare your life.', 'monkey, you have to wake up.', 'I have orders to kill her.', \"I'm not going to breed kids with a genetic disorder that makes them die.\", \"they're laughing at us. We'll show you.\", \"there wasn't much black in Maine then.\", 'Briggs, what the hell is going on?', \"another simply didn't know what to do, so whenever he met my brother, he nearly beat the shit out of him.\"]\n"
          ]
        }
      ],
      "source": [
        "print(list(data['text'])[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yKd2OKPx160",
        "outputId": "4ec9e00e-08ca-4d8a-8b60-ca0690d72c07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99022484 0.24870145]\n"
          ]
        }
      ],
      "source": [
        "lst = text2toxicity(list(data['text'])[:10], True)\n",
        "print(lst[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS4dE_kYx160",
        "outputId": "34bf2757-f4cc-410e-a4c8-01f923a8d27c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.9819834232330322, 0.99022484),\n",
              " (0.9990390539169312, 0.24870145),\n",
              " (0.98506760597229, 0.31828928),\n",
              " (0.9942149519920348, 0.6044049),\n",
              " (0.9993481040000916, 0.9975751),\n",
              " (0.0358464829623699, 0.3226593),\n",
              " (0.0001314068067586, 0.07216662),\n",
              " (0.148709550499916, 0.16785556),\n",
              " (0.8410708904266357, 0.23996061),\n",
              " (0.9304717183113098, 0.58641845)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "sh = list(zip(list(data['toxicity_score'])[:10], lst[:10]))\n",
        "sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So9ju_qJx160",
        "outputId": "1b03827c-3ddf-43c5-95a8-46ebdca5c5b3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are large difference, so I think I need train this model by adding new linear layers"
      ],
      "metadata": {
        "collapsed": false,
        "id": "sQk2iQSJx160"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's preprocess data to train our model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Uxky8dsix161"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW2KaTpvgbG3",
        "outputId": "d88a2510-8587-4262-b4c5-afbbc54d69c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1155552"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think I reduced data because if not, training will be very long"
      ],
      "metadata": {
        "id": "ZxX3uUBMgfJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.iloc[:200000, :]"
      ],
      "metadata": {
        "id": "dDQkUrnngeVO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['if Alkar floods her with her mental waste, it would explain the high levels of neurotransmitter.'\n",
            " \"you're becoming disgusting.\"] [[9.81983423e-01 1.80165768e-02]\n",
            " [9.99039054e-01 9.60946083e-04]]\n"
          ]
        }
      ],
      "source": [
        "sentences = np.array(list(data['text']))\n",
        "targets = np.array(list(zip(list(data['toxicity_score']), list(1 - data['toxicity_score']))))\n",
        "print(sentences[:2], targets[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN2YjniKx161",
        "outputId": "32ea3d27-7e83-4670-8741-3ff51acfdb14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.13481990650029438\n",
            "Epoch 2, Loss: 0.10675954302329846\n",
            "Epoch 3, Loss: 0.09861405799760843\n",
            "Epoch 4, Loss: 0.09281198428872296\n",
            "Epoch 5, Loss: 0.08917331304925177\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "\n",
        "model_checkpoint = 'cointegrated/rubert-tiny-toxicity'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, test=False):\n",
        "        if not test and labels is None:\n",
        "            raise Exception(\"You should passed labels when you use this dataset for training!\")\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.test = test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = tokenizer(self.texts[idx], truncation=True, padding='max_length', max_length=128,\n",
        "                             return_tensors='pt')\n",
        "        res = {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "        }\n",
        "        if not self.test:\n",
        "            res['labels'] = torch.tensor(self.labels[idx])\n",
        "        return res\n",
        "\n",
        "dataset = CustomDataset(sentences, targets)\n",
        "data_loader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "class CustomClassifier(nn.Module):\n",
        "    def __init__(self, model, device):\n",
        "        super(CustomClassifier, self).__init__()\n",
        "        self.model = model\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(5, 5),\n",
        "            nn.Linear(5, 2),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "        self.classifier.to(device)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = self.classifier(outputs.logits)\n",
        "        return logits\n",
        "\n",
        "\n",
        "classifier = CustomClassifier(model, device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(5):\n",
        "    classifier.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in data_loader:\n",
        "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
        "\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = classifier(input_ids, attention_mask).to(device)\n",
        "        loss = criterion(logits.float(), labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(data_loader)}\")\n",
        "    save_path = f\"evaluting_toxicity_model_{epoch}.pth\"\n",
        "    torch.save({\n",
        "    'model_state_dict': classifier.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'epoch': epoch,\n",
        "    'loss': total_loss / len(data_loader)\n",
        "    }, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKNqy7lrx161",
        "outputId": "b21f3766-a70e-41c4-dab2-bce26fa808a0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"you're still in trouble, aren't you?\"\n",
            " 'before you go, Officer, could you just kill the spider I caught under the cup?']\n",
            "[0.00041122 0.07897831]\n",
            "tensor([0.0379, 0.6970], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Example text to predict\n",
        "texts_to_predict = sentences[200:202]\n",
        "\n",
        "# Create a data loader for prediction\n",
        "dataset = CustomDataset(texts_to_predict, test=True)\n",
        "data_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "        input_ids, attention_mask = batch['input_ids'], batch['attention_mask']\n",
        "        if torch.cuda.is_available():\n",
        "            input_ids, attention_mask = input_ids.to('cuda'), attention_mask.to('cuda')\n",
        "\n",
        "        logits = classifier(input_ids, attention_mask)\n",
        "        predictions = logits[:, 0]\n",
        "print(texts_to_predict)\n",
        "print(targets[200:202, 0])\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFFC95-Ox162",
        "outputId": "dc567e11-e51b-4e93-a85b-85161e90ed42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:** this is not working well :( So I will use the function `text2toxicity` that I coded above to estimate toxicity of the text."
      ],
      "metadata": {
        "id": "7iJVNZJDthGf"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}